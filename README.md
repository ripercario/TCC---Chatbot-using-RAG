# Assistente Virtual com IA para Consulta de Documentos Corporativos

**Status do Projeto: Em Desenvolvimento (ProtÃ³tipo Funcional)**

Este repositÃ³rio contÃ©m o cÃ³digo-fonte do projeto de Trabalho de ConclusÃ£o de Curso (TCC) em Engenharia de ComputaÃ§Ã£o, que consiste em um chatbot inteligente projetado para otimizar o acesso Ã  informaÃ§Ã£o em manuais e documentos operacionais de uma empresa.

## ğŸ“– VisÃ£o Geral

Em ambientes corporativos, especialmente em setores como a logÃ­stica, a informaÃ§Ã£o crÃ­tica estÃ¡ frequentemente dispersa em extensos arquivos PDF, muitas vezes contendo diagramas, tabelas e imagens. Isso torna a busca por procedimentos especÃ­ficos uma tarefa lenta e ineficiente.

Este projeto implementa uma soluÃ§Ã£o avanÃ§ada de **RAG (Retrieval-Augmented Generation)** que permite aos colaboradores fazerem perguntas em linguagem natural e receberem respostas precisas e contextuais, extraÃ­das diretamente dos documentos da empresa, incluindo texto dentro de imagens.

## âœ¨ Features

* **Busca SemÃ¢ntica:** Entende o significado da pergunta, nÃ£o apenas as palavras-chave.
* **OCR (Reconhecimento Ã“ptico de Caracteres):** Capaz de extrair e indexar texto de imagens e diagramas dentro dos PDFs.
* **AtualizaÃ§Ã£o Incremental:** Permite adicionar novos documentos Ã  base de conhecimento sem a necessidade de reprocessar todos os arquivos existentes.
* **Interface de Chat Intuitiva:** Utiliza Chainlit para uma experiÃªncia de usuÃ¡rio moderna e interativa.
* **Arquitetura 100% Local:** Roda inteiramente na mÃ¡quina do usuÃ¡rio, garantindo a privacidade e a seguranÃ§a dos dados.

## ğŸ—ï¸ Arquitetura

O sistema Ã© dividido em trÃªs camadas lÃ³gicas principais:

1.  **Interface (Frontend):** ConstruÃ­da com **Chainlit**, Ã© a camada de apresentaÃ§Ã£o responsÃ¡vel pelo fluxo de interaÃ§Ã£o com o usuÃ¡rio.
2.  **LÃ³gica da AplicaÃ§Ã£o (Backend):** Orquestra os processos, conectando a interface Ã  pipeline de IA.
    * Recebe a pergunta do usuÃ¡rio via `app.py`.
    * Utiliza o `chatbot.py` para coordenar a busca e a geraÃ§Ã£o da resposta.

3.  **Pipeline de Dados e IA (RAG Core):** ContÃ©m os componentes de InteligÃªncia Artificial que sÃ£o a base da soluÃ§Ã£o.
    * **IngestÃ£o de Documentos:** Utiliza `Unstructured` com **Tesseract** e **Poppler** para um processamento robusto de PDFs, extraindo texto de forma eficaz, inclusive de imagens (OCR).
    * **Modelo de Embedding:** Usa o **Snowflake Arctic (`snowflake-arctic-embed-m`)** para converter os trechos de texto em vetores numÃ©ricos de alta qualidade.
    * **Ãndice Vetorial:** Armazena os vetores em um Ã­ndice **FAISS** local para buscas rÃ¡pidas por similaridade.
    * **Modelo de Linguagem (LLM):** O **Llama 3**, rodando via **Ollama**, recebe o contexto recuperado pelo FAISS e gera a resposta final em linguagem natural.

## ğŸ› ï¸ Tecnologias Utilizadas

-   **Linguagem:** Python 3.11 (recomendado para maior compatibilidade)
-   **Interface:** Chainlit
-   **Modelo de Linguagem (LLM):** Llama 3 (via Ollama)
-   **Modelo de Embedding:** Snowflake Arctic (`snowflake-arctic-embed-m`)
-   **Ãndice Vetorial:** FAISS
-   **ManipulaÃ§Ã£o de PDF e OCR:** Unstructured, Tesseract, Poppler
-   **Ambiente Virtual:** venv

## ğŸš€ Como Executar o Projeto

Siga os passos abaixo para configurar e rodar o projeto em seu ambiente local.

### 1. PrÃ©-requisitos

-   Python 3.11 ou superior
-   [Ollama](https://ollama.com/) instalado e em execuÃ§Ã£o.
-   **Tesseract OCR:** Instalado e com seu caminho adicionado Ã  variÃ¡vel de ambiente `PATH` do sistema.
-   **Poppler:** UtilitÃ¡rios baixados e com a pasta `bin` adicionada Ã  variÃ¡vel de ambiente `PATH` do sistema.

### 2. InstalaÃ§Ã£o

**a. Clone o repositÃ³rio:**
```bash
git clone [https://github.com/ripercario/TCC---Chatbot-using-RAG.git](https://github.com/ripercario/TCC---Chatbot-using-RAG.git)
cd TCC---Chatbot-using-RAG
```

**b. Crie e ative um ambiente virtual:**
```bash
# Windows
python -m venv .venv
.\.venv\Scripts\activate


# macOS / Linux
python3 -m venv .venv
source .venv/bin/activate
```

**c. Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

**d. Baixe o modelo Llama 3 via Ollama:**
```bash
ollama pull llama3
```

### 3. ConfiguraÃ§Ã£o

**a. Adicione os seus documentos:**
Coloque todos os manuais e documentos em formato `.pdf` em um caminho, que serÃ¡ passado para o `create_index.py`.

**b. Crie o Ã­ndice vetorial:**
Execute o script `create_index.py` para processar os PDFs e criar o banco de dados vetorial FAISS.
python create_index.py
```

ObservaÃ§Ã£o: Este processo pode ser lento na primeira vez devido ao OCR. Ele sÃ³ precisa ser executado quando novos documentos sÃ£o adicionados.

Ao final do processo, uma nova pasta chamada `data/faiss_index` serÃ¡ criada.

### 4. ExecuÃ§Ã£o

Com o Ollama em execuÃ§Ã£o em segundo plano, inicie a aplicaÃ§Ã£o Chainlit:
```bash
chainlit run app/app.py -w
```
A flag `-w` (watch) reinicia o servidor automaticamente sempre que vocÃª salvar uma alteraÃ§Ã£o no cÃ³digo.

Abra o seu navegador e acesse `http://localhost:8000` para comeÃ§ar a interagir com o chatbot.

## ğŸ“ Estrutura do Projeto
```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py          # LÃ³gica da interface com Chainlit
â”‚   â”œâ”€â”€ chatbot.py      # LÃ³gica de orquestraÃ§Ã£o e chamada ao modelo
â”‚   â””â”€â”€ rag_pipeline.py # FunÃ§Ãµes de criaÃ§Ã£o e consulta do Ã­ndice RAG   
â”œâ”€â”€ data/
â”‚   â””â”€â”€ faiss_index/    # Criado/atualizado apÃ³s a execuÃ§Ã£o de create_index.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ chainlit.md
â”œâ”€â”€ create_index.py     # Script para criar/atualizar o Ã­ndice vetorial
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## âœ’ï¸ Autor

-   **Ricardo Percario de Souza Ribeiro** 